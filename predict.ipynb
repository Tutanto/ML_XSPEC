{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "import emcee\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from joblib import load\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import display, Math\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from modules.network import r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "result_path = cwd /'results'\n",
    "data_file_path = cwd /'data'\n",
    "\n",
    "xd = np.load(data_file_path / 'x_true.npy', allow_pickle=True)\n",
    "yd = np.load(data_file_path / 'y_true.npy', allow_pickle=True)\n",
    "yderr = np.load(data_file_path / 'yerr.npy', allow_pickle=True)\n",
    "\n",
    "model = load_model(result_path / 'ANN_model.h5', custom_objects={'r_squared': r_squared})\n",
    "# Load the saved scaler\n",
    "flux_scaler = load(data_file_path / 'flux_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(x, m, b):\n",
    "    x_grid = np.linspace(-10, 10, 100)\n",
    "    params = [m, b]\n",
    "    y_pred = model.predict([params], verbose=0)\n",
    "    y_pred_d = flux_scaler.inverse_transform(y_pred)\n",
    "\n",
    "    return np.interp(x, x_grid, y_pred_d[0])\n",
    "\n",
    "def log_likelihood(theta):\n",
    "    m, b, log_f = theta\n",
    "    model = Model(xd, m, b)\n",
    "    sigma2 = yderr**2 + model**2 * np.exp(2 * log_f)\n",
    "#    sigma2 = yerr**2 + np.exp(2 * log_f)\n",
    "    return -0.5 * np.sum((yd - model) ** 2 / sigma2 + np.log(sigma2))\n",
    "\n",
    "def log_prior(theta):\n",
    "    m, b, log_f = theta\n",
    "    if (-5 < m < 5) and (-10 < b < 10) and (-10.0 < log_f < 1.0):\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def log_probability(theta):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# The \"true\" parameters.\n",
    "m_true = -0.9594\n",
    "b_true = 4.294\n",
    "f_true = 0.534\n",
    "\n",
    "nll = lambda *args: -log_likelihood(*args)\n",
    "initial = np.array([m_true, b_true, np.log(f_true)]) + 0.1 * np.random.randn(3)\n",
    "soln = minimize(nll, initial)\n",
    "m_ml, b_ml, log_f_ml = soln.x\n",
    "\n",
    "print(\"Maximum likelihood estimates:\")\n",
    "print(\"m = {0:.3f}\".format(m_ml))\n",
    "print(\"b = {0:.3f}\".format(b_ml))\n",
    "print(\"f = {0:.3f}\".format(np.exp(log_f_ml)))\n",
    "\n",
    "plt.errorbar(xd, yd, yerr=yderr, fmt=\".c\", capsize=0)\n",
    "plt.plot(xd, m_true * xd + b_true, \"c\", alpha=0.3, lw=3, label=\"truth\")\n",
    "plt.plot(xd, Model(xd, m_ml, b_ml), \":c\", label=\"ML\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = soln.x[:2]\n",
    "guess_par = params\n",
    "\n",
    "init = soln.x\n",
    "\n",
    "pos = init + 1e-2 * np.random.randn(48, len(init))\n",
    "nwalkers, ndim = pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print('start sampler')\n",
    "\n",
    "'''with Pool() as pool:\n",
    "    sampler = emcee.EnsembleSampler(\n",
    "        nwalkers, ndim, log_probability, pool=pool\n",
    "    )\n",
    "\n",
    "    sampler.run_mcmc(pos, 1000, progress=True)\n",
    "'''\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability)\n",
    "sampler.run_mcmc(pos, 1000, progress=True)\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
    "samples = sampler.get_chain()\n",
    "labels = [\"m\", \"b\",'logf']\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"c\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = sampler.get_autocorr_time()\n",
    "print(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_samples = sampler.get_chain(discard=100, thin=15, flat=True)\n",
    "print(flat_samples.shape)\n",
    "\n",
    "\n",
    "for i in range(ndim):\n",
    "    mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])\n",
    "    q = np.diff(mcmc)\n",
    "    txt = \"\\mathrm{{{3}}} = {0:.3f}_{{-{1:.3f}}}^{{{2:.3f}}}\"\n",
    "    txt = txt.format(mcmc[1], q[0], q[1], labels[i])\n",
    "    display(Math(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_samples = sampler.get_chain(discard=100, thin=15, flat=True)\n",
    "fig = corner.corner(\n",
    "    flat_samples, labels=labels, truths=[m_true, b_true, np.log(f_true)],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
